<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="有监督学习的两种主要任务（分类和回归） 有监督机器学习任务主要分为两种，一种是分类任务，一般是通过学习算法实现对未知数据的分类甄别，比如判断是男性还是女性，预测明天会不会下雨等等，预测结果是离散的分类。另一种是回归任务，用于预测一个具体的值，比如房价、年龄等等，预测结果是连续的值； 解决回归任务比较常见的算法就是线性回归算法； 线性回归 线性回归是最典型的用于回归任务的机器学习算法。它的基本原理是基于，任意一个为n的值，可以通过一个n-1阶的多项式进行拟合； 线性回归的算法的目标是根据已知标签数据，训练一个预测函数f(a, b)，使得x输入带入ax+b这样的多项式可以得出需要预测的值； 所以目标是找到合适的a和b（从数学语言的精确描述来说，一般用别的符号代替，为了方便记录，我使用a和b）； 为了找到合适的a和b，需要定义一个损失函数（也有称为代价函数的），J(a, b)，用于判断a和b是否合适，比较简单的有“方差均值”法； 方差均值指的是，所有样本带入预测函数f，将预测值与实际值相减，取平方，求和再求平均数（暂时不知到markdown里如何加入公式）； 那么带入损失函数，就是意味着，找到合适的a、b使得刚才那个方差均值小于一个阈值（接近最优）； 线性回归本质上，是在平面坐标系里找到一个与样本匹配的直线，这样基于这个直线，即可预测未知的值； 梯度下降 如何找到合适的a和b，一个一个地去试是不可能的（无穷多的计算量）； 比较典型的算法是“梯度下降”，又是牛顿起的头； 比较生动的描述是，想想一个三维空间图形，X和Y平面是有a和b的值构成，Z轴是损失函数的值，值最小的部分（在图上就最低的部分，像一个山谷）就是最优解； 从山顶的某个点上，环顾360度，找到适合下山的一小步，一点一点儿走向山谷最低处，有点像慢慢走楼梯，所以叫梯度下降； 从我的体会来看，这个方法有点像牛顿那个计算平方根的迭代法（根据一个猜测值，然后通过迭代公式寻找一个更加接近正确值的值，直到误差降低到合适范围）； 从微积分的角度，就是找到损失函数J在最初尝试的那个点上的切线，并通过它的斜率（也就是导数值）乘以一个系数a，逐步逼近最低点（切线斜率为零）的过程； "><title>线性回归和梯度下降</title>
<link rel=canonical href=https://sbabybird.github.io/p/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%92%8C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/><link rel=stylesheet href=/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css><meta property='og:title' content="线性回归和梯度下降"><meta property='og:description' content="有监督学习的两种主要任务（分类和回归） 有监督机器学习任务主要分为两种，一种是分类任务，一般是通过学习算法实现对未知数据的分类甄别，比如判断是男性还是女性，预测明天会不会下雨等等，预测结果是离散的分类。另一种是回归任务，用于预测一个具体的值，比如房价、年龄等等，预测结果是连续的值； 解决回归任务比较常见的算法就是线性回归算法； 线性回归 线性回归是最典型的用于回归任务的机器学习算法。它的基本原理是基于，任意一个为n的值，可以通过一个n-1阶的多项式进行拟合； 线性回归的算法的目标是根据已知标签数据，训练一个预测函数f(a, b)，使得x输入带入ax+b这样的多项式可以得出需要预测的值； 所以目标是找到合适的a和b（从数学语言的精确描述来说，一般用别的符号代替，为了方便记录，我使用a和b）； 为了找到合适的a和b，需要定义一个损失函数（也有称为代价函数的），J(a, b)，用于判断a和b是否合适，比较简单的有“方差均值”法； 方差均值指的是，所有样本带入预测函数f，将预测值与实际值相减，取平方，求和再求平均数（暂时不知到markdown里如何加入公式）； 那么带入损失函数，就是意味着，找到合适的a、b使得刚才那个方差均值小于一个阈值（接近最优）； 线性回归本质上，是在平面坐标系里找到一个与样本匹配的直线，这样基于这个直线，即可预测未知的值； 梯度下降 如何找到合适的a和b，一个一个地去试是不可能的（无穷多的计算量）； 比较典型的算法是“梯度下降”，又是牛顿起的头； 比较生动的描述是，想想一个三维空间图形，X和Y平面是有a和b的值构成，Z轴是损失函数的值，值最小的部分（在图上就最低的部分，像一个山谷）就是最优解； 从山顶的某个点上，环顾360度，找到适合下山的一小步，一点一点儿走向山谷最低处，有点像慢慢走楼梯，所以叫梯度下降； 从我的体会来看，这个方法有点像牛顿那个计算平方根的迭代法（根据一个猜测值，然后通过迭代公式寻找一个更加接近正确值的值，直到误差降低到合适范围）； 从微积分的角度，就是找到损失函数J在最初尝试的那个点上的切线，并通过它的斜率（也就是导数值）乘以一个系数a，逐步逼近最低点（切线斜率为零）的过程； "><meta property='og:url' content='https://sbabybird.github.io/p/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%92%8C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/'><meta property='og:site_name' content='Learning & Writing！'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='AI'><meta property='article:published_time' content='2019-06-02T00:00:00+00:00'><meta property='article:modified_time' content='2019-06-02T00:00:00+00:00'><meta name=twitter:title content="线性回归和梯度下降"><meta name=twitter:description content="有监督学习的两种主要任务（分类和回归） 有监督机器学习任务主要分为两种，一种是分类任务，一般是通过学习算法实现对未知数据的分类甄别，比如判断是男性还是女性，预测明天会不会下雨等等，预测结果是离散的分类。另一种是回归任务，用于预测一个具体的值，比如房价、年龄等等，预测结果是连续的值； 解决回归任务比较常见的算法就是线性回归算法； 线性回归 线性回归是最典型的用于回归任务的机器学习算法。它的基本原理是基于，任意一个为n的值，可以通过一个n-1阶的多项式进行拟合； 线性回归的算法的目标是根据已知标签数据，训练一个预测函数f(a, b)，使得x输入带入ax+b这样的多项式可以得出需要预测的值； 所以目标是找到合适的a和b（从数学语言的精确描述来说，一般用别的符号代替，为了方便记录，我使用a和b）； 为了找到合适的a和b，需要定义一个损失函数（也有称为代价函数的），J(a, b)，用于判断a和b是否合适，比较简单的有“方差均值”法； 方差均值指的是，所有样本带入预测函数f，将预测值与实际值相减，取平方，求和再求平均数（暂时不知到markdown里如何加入公式）； 那么带入损失函数，就是意味着，找到合适的a、b使得刚才那个方差均值小于一个阈值（接近最优）； 线性回归本质上，是在平面坐标系里找到一个与样本匹配的直线，这样基于这个直线，即可预测未知的值； 梯度下降 如何找到合适的a和b，一个一个地去试是不可能的（无穷多的计算量）； 比较典型的算法是“梯度下降”，又是牛顿起的头； 比较生动的描述是，想想一个三维空间图形，X和Y平面是有a和b的值构成，Z轴是损失函数的值，值最小的部分（在图上就最低的部分，像一个山谷）就是最优解； 从山顶的某个点上，环顾360度，找到适合下山的一小步，一点一点儿走向山谷最低处，有点像慢慢走楼梯，所以叫梯度下降； 从我的体会来看，这个方法有点像牛顿那个计算平方根的迭代法（根据一个猜测值，然后通过迭代公式寻找一个更加接近正确值的值，直到误差降低到合适范围）； 从微积分的角度，就是找到损失函数J在最初尝试的那个点上的切线，并通过它的斜率（也就是导数值）乘以一个系数a，逐步逼近最低点（切线斜率为零）的过程； "><link rel="shortcut icon" href=/favicon.png><script async src="https://www.googletagmanager.com/gtag/js?id=G-CEXC06LBF4"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-CEXC06LBF4")}</script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?93ac531a5d8f2fd906f5aafc5aa1685f",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6151777552509349" crossorigin=anonymous></script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu12360362506187142519.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🌝</span></figure><div class=site-meta><h1 class=site-name><a href=/>Learning & Writing！</a></h1><h2 class=site-description>My reading and studying notes.</h2></div></header><ol class=menu-social><li><a href=https://github.com/sbabybird target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://twitter.com/sbabybird target=_blank title=Twitter rel=me><svg class="icon icon-tabler icon-tabler-brand-twitter" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M22 4.01c-1 .49-1.98.689-3 .99-1.121-1.265-2.783-1.335-4.38-.737S11.977 6.323 12 8v1c-3.245.083-6.135-1.395-8-4 0 0-4.182 7.433 4 11-1.872 1.247-3.739 2.088-6 2 3.308 1.803 6.913 2.423 10.034 1.517 3.58-1.04 6.522-3.723 7.651-7.742a13.84 13.84.0 00.497-3.753C20.18 7.773 21.692 5.25 22 4.009z"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><ol><li><a href=#有监督学习的两种主要任务分类和回归>有监督学习的两种主要任务（分类和回归）</a></li><li><a href=#线性回归>线性回归</a></li><li><a href=#梯度下降>梯度下降</a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/>技术研究</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%92%8C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/>线性回归和梯度下降</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Jun 02, 2019</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 2 分钟</time></div></footer></div></header><section class=article-content><h3 id=有监督学习的两种主要任务分类和回归>有监督学习的两种主要任务（分类和回归）</h3><ul><li>有监督机器学习任务主要分为两种，一种是分类任务，一般是通过学习算法实现对未知数据的分类甄别，比如判断是男性还是女性，预测明天会不会下雨等等，预测结果是离散的分类。另一种是回归任务，用于预测一个具体的值，比如房价、年龄等等，预测结果是连续的值；</li><li>解决回归任务比较常见的算法就是线性回归算法；</li></ul><h3 id=线性回归>线性回归</h3><ul><li>线性回归是最典型的用于回归任务的机器学习算法。它的基本原理是基于，任意一个为n的值，可以通过一个n-1阶的多项式进行拟合；</li><li>线性回归的算法的目标是根据已知标签数据，训练一个预测函数f(a, b)，使得x输入带入ax+b这样的多项式可以得出需要预测的值；</li><li>所以目标是找到合适的a和b（从数学语言的精确描述来说，一般用别的符号代替，为了方便记录，我使用a和b）；</li><li>为了找到合适的a和b，需要定义一个损失函数（也有称为代价函数的），J(a, b)，用于判断a和b是否合适，比较简单的有“方差均值”法；</li><li>方差均值指的是，所有样本带入预测函数f，将预测值与实际值相减，取平方，求和再求平均数（暂时不知到markdown里如何加入公式）；</li><li>那么带入损失函数，就是意味着，找到合适的a、b使得刚才那个方差均值小于一个阈值（接近最优）；</li><li>线性回归本质上，是在平面坐标系里找到一个与样本匹配的直线，这样基于这个直线，即可预测未知的值；</li></ul><h3 id=梯度下降>梯度下降</h3><ul><li>如何找到合适的a和b，一个一个地去试是不可能的（无穷多的计算量）；</li><li>比较典型的算法是“梯度下降”，又是牛顿起的头；</li><li>比较生动的描述是，想想一个三维空间图形，X和Y平面是有a和b的值构成，Z轴是损失函数的值，值最小的部分（在图上就最低的部分，像一个山谷）就是最优解；</li><li>从山顶的某个点上，环顾360度，找到适合下山的一小步，一点一点儿走向山谷最低处，有点像慢慢走楼梯，所以叫梯度下降；</li><li>从我的体会来看，这个方法有点像牛顿那个计算平方根的迭代法（根据一个猜测值，然后通过迭代公式寻找一个更加接近正确值的值，直到误差降低到合适范围）；</li><li>从微积分的角度，就是找到损失函数J在最初尝试的那个点上的切线，并通过它的斜率（也就是导数值）乘以一个系数a，逐步逼近最低点（切线斜率为零）的过程；</li></ul></section><footer class=article-footer><section class=article-tags><a href=/tags/ai/>AI</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%AD%A6%E4%B9%A0%E5%87%86%E5%A4%87/><div class=article-details><h2 class=article-title>机器学习的学习准备</h2></div></a></article><article><a href=/p/win8%E7%B3%BB%E7%BB%9F%E4%B8%8B%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0%E6%9C%AC%E4%BD%9C%E4%B8%BAwifi%E7%83%AD%E7%82%B9/><div class=article-details><h2 class=article-title>win8系统下使用笔记本作为wifi热点</h2></div></a></article><article><a href=/p/%E4%BD%BF%E7%94%A8vs2008%E7%BC%96%E8%AF%91mongodb/><div class=article-details><h2 class=article-title>使用vs2008编译mongodb</h2></div></a></article></div></div></aside><script src=https://utteranc.es/client.js repo=sbabybird/sbabybird.github.com issue-term=pathname crossorigin=anonymous async></script><style>.utterances{max-width:unset}</style><script>let utterancesLoaded=!1;function setUtterancesTheme(e){let t=document.querySelector(".utterances iframe");t&&t.contentWindow.postMessage({type:"set-theme",theme:`github-${e}`},"https://utteranc.es")}addEventListener("message",e=>{if(e.origin!=="https://utteranc.es")return;utterancesLoaded=!0,setUtterancesTheme(document.documentElement.dataset.scheme)}),window.addEventListener("onColorSchemeChange",e=>{if(!utterancesLoaded)return;setUtterancesTheme(e.detail)})</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2025 Learning & Writing！</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.31.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>